This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
src/
  bridge/
    cb_registration.cpp
    cb_registration.hpp
    cb_validation.cpp
    cb_validation.hpp
    py_trampoline.c
    py_trampoline.h
    pybridge.cpp
    pybridge.h
  pyencoder/
    environment/
      __init__.py
      av1_env.py
    utils/
      video_reader.py
    __init__.py
    _binding.cpp
CMakeLists.txt
pyproject.toml
run_env.py
test.py

================================================================
Files
================================================================

================
File: src/bridge/cb_registration.cpp
================
#include "cb_registration.hpp"
#include "cb_validation.hpp"
#include "pybridge.hpp"

namespace py = pybind11;
using bridge::CallbackEnum;

namespace bridge {

Callback g_callbacks[static_cast<int>(CallbackEnum::Count)] = {
    /* GetDeltaQOffset     */ { py::none(), nullptr, "(LTuii)L", 4 },
    /* RecvFrameFeedback   */ { py::none(), nullptr, "(iiiiTTT)v", 7 },
    /* RecvPictureFeedback */ { py::none(), nullptr, "(Ti)v", 2 },
};

static int set_cb_ptr(CallbackEnum which, bool unset)
{
    switch (which) {
        case CallbackEnum::GetDeltaQOffset:
            get_deltaq_offset_cb = unset ? nullptr : get_deltaq_offset_trampoline;
            return 0;
        case CallbackEnum::RecvFrameFeedback:
            recv_frame_feedback_cb = unset ? nullptr : recv_frame_feedback_trampoline;
            return 0;
        case CallbackEnum::RecvPictureFeedback:
            recv_picture_feedback = unset ? nullptr : recv_picture_feedback_trampoline;
            return 0;
        default:
            return -1;
    }
}

static int clear_slot(CallbackEnum which)
{
    g_callbacks[static_cast<int>(which)].py_func = py::none();  // RAII decref
    return set_cb_ptr(which, /*unset=*/true);
}

int pybridge_set_cb(CallbackEnum which, py::object callable)
{
    Callback &slot = g_callbacks[static_cast<int>(which)];

    // Store new function
    slot.py_func = std::move(callable);

    // Enable the C trampoline for the encoder
    return set_cb_ptr(which, callable.is_none());
}

} // namespace bridge

================
File: src/bridge/cb_registration.hpp
================
#pragma once
#include <pybind11/pybind11.h>

namespace pybridge {

enum class CallbackEnum {
    GetDeltaQOffset,
    RecvFrameFeedback,
    RecvPictureFeedback,
    Count
};

struct Callback {
    pybind11::function py_func;
    void            *c_trampoline;
    const char      *cb_fmt;
    int              n_args;
};

extern Callback g_callbacks[static_cast<int>(CallbackEnum::Count)];

int pybridge_set_cb(CallbackEnum which, pybind11::object callable);

} // namespace pybridge

================
File: src/bridge/cb_validation.cpp
================
#include "cb_validation.hpp"

#include <pybind11/pybind11.h>
#include <pybind11/functional.h>
#include <Python.h>

#include <cassert>

namespace py  = pybind11;

namespace pybridge {

py::function validate_callable(const py::object &callable, int expected_n_args)
{
    assert(PyGILState_Check());

    if (!PyCallable_Check(callable.ptr())) {
        throw py::type_error("object must be callable");
    }

    // verify __code__ object
    py::object code_obj = callable.attr("__code__");
    if (!PyCode_Check(code_obj.ptr())) {
        throw py::type_error("callable has no valid __code__");
    }

    // Grab arg numbers
    PyCodeObject *co = reinterpret_cast<PyCodeObject *>(code_obj.ptr());
    const int nargs       = co->co_argcount + co->co_posonlyargcount;
    const bool has_vararg = (co->co_flags & CO_VARARGS)     != 0;
    const bool has_varkw  = (co->co_flags & CO_VARKEYWORDS) != 0;

    if (has_vararg || has_varkw) {
        throw py::type_error("callback may not use *args or **kwargs");
    }

    if (nargs != expected_n_args) {
        throw py::type_error(
            "callback must take exactly " + std::to_string(expected_n_args) + " positional arguments (got " + std::to_string(nargs) + ")"
        );
    }

    // Return as a function
    return py::reinterpret_borrow<py::function>(callable);
}

}

================
File: src/bridge/cb_validation.hpp
================
#pragma once
#include <pybind11/pybind11.h>

namespace pybridge {

py::function validate_callable(const py::object &callable, int expected_n_args);

} // namespace pybridge

================
File: src/bridge/py_trampoline.c
================
// #include "py_trampoline.h"
// #include "cb_validation.h"
// #include "../../../Source/API/EbSvtAv1Enc.h"
// #include <regex.h>
// #include <stdbool.h>
// #include <stdint.h>

// typedef union {
//     int8_t   i8;  uint8_t  u8;
//     int16_t i16;  uint16_t u16;
//     int32_t i32;  uint32_t u32;
//     int64_t i64;  uint64_t u64;
//     double   d; const void *p;
// } ArgBuf;

// static PyObject *PyConvert(char code, const void *addr)
// {
//     switch (code) {
//         case 'c':  return PyLong_FromLong(*(const int8_t  *)addr);
//         case 'C':  return PyLong_FromUnsignedLong(*(const uint8_t *)addr);
//         case 'h':  return PyLong_FromLong(*(const int16_t *)addr);
//         case 'H':  return PyLong_FromUnsignedLong(*(const uint16_t*)addr);
//         case 'i':  return PyLong_FromLong(*(const int32_t *)addr);
//         case 'u':  return PyLong_FromUnsignedLong(*(const uint32_t*)addr);
//         case 'q':  return PyLong_FromLongLong(*(const int64_t *)addr);
//         case 'Q':  return PyLong_FromUnsignedLongLong(*(const uint64_t*)addr);
//         case 'd':  return PyFloat_FromDouble(*(const double*)addr);
//         case 'b':  return PyBool_FromLong(*(const int32_t*)addr);
//         case 's':  return PyUnicode_FromString(*(const char *const *)addr);
//         case 'O': {
//             PyObject *o = *(PyObject *const *)addr;
//             Py_XINCREF(o);
//             return o;
//         }
//         default:
//             PyErr_Format(PyExc_ValueError, "unknown element code '%c'", code);
//             return NULL;
//     }
// }

// static inline size_t elem_size(char code)
// {
//     switch (code) {
//         case 'c': case 'C': return sizeof(uint8_t);
//         case 'h': case 'H': return sizeof(uint16_t);
//         case 'i': case 'u': case 'b': return sizeof(uint32_t);
//         case 'q': case 'Q': case 'd': return sizeof(uint64_t);
//         case 'T': case 'O': case 's': return sizeof(void *);
//         default: return sizeof(int);
//     }
// }

// static PyObject *PyList_Create(char code, const void **buf, int len, PyObject *(*transform)(void *))
// {
//     fprintf(stderr, "%p\n", buf[0]);
//     if (!buf || len < 0) {
//         PyErr_SetString(PyExc_ValueError, "invalid buffer/length for list");
//         return NULL;
//     }

//     PyObject *list = PyList_New(len);
//     if (!list) {
//         PyErr_Print();
//         return NULL;
//     }

//     size_t esz = elem_size(code);
//     const char *base = (const char *)buf;

//     for (int i = 0; i < len; ++i) {
//         PyObject *item = NULL;

//         if (code == 'T') {
//             void *ptr = buf[i];
//             item = transform(ptr);
//             if (!item) {
//                 Py_DECREF(list);
//                 PyErr_Print();
//                 return NULL;
//             }
//             if (item == Py_None)
//                 Py_INCREF(Py_None);
//         } else {
//             const void *addr = base + (size_t)i * esz;
//             item = PyConvert(code, addr);
//         }

//         if (!item) {
//             Py_DECREF(list);
//             PyErr_Print();
//             return NULL;
//         }

//         if (PyList_SetItem(list, i, item) < 0) {
//             Py_DECREF(list);
//             PyErr_Print();
//             return NULL;
//         }
//     }

//     return list;
// }

// static PyObject *PyMat_Create(char code, const void *buf, int w, int h, PyObject *(*transform)(void *))
// {
//     if (!buf || w <= 0 || h <= 0) {
//         PyErr_SetString(PyExc_ValueError, "invalid buffer/dimensions for matrix");
//         return NULL;
//     }

//     PyObject *mat = PyList_New(h);
//     if (!mat) {
//         PyErr_Print();
//         return NULL;
//     }

//     size_t esz = elem_size(code);
//     const char *base = (const char *)buf;

//     for (int r = 0; r < h; ++r) {
//         const void *row_start = base + (size_t)r * w * esz;
//         PyObject *row = PyList_Create(code, row_start, w, transform);
//         if (!row) {
//             Py_DECREF(mat);
//             PyErr_Print();
//             return NULL;
//         }
//         if (PyList_SetItem(mat, r, row) < 0) {
//             Py_DECREF(row);
//             Py_DECREF(mat);
//             PyErr_Print();
//             return NULL;
//         }
//     }

//     return mat;
// }

// static int
// PyReadArgs(const char *fmt, PyObject *tuple, va_list ap, char *retcode_out)
// {
//     int pos = 0;
//     for (const char *p = fmt + 1; *p && *p != ')'; ++p) {
//         char code = *p;
//         PyObject *arg = NULL;

//         if (code == 'L' || code == 'M') {                /* containers */
//             char sub = *++p;
//             if (!sub || sub == ')') {
//                 PyErr_SetString(PyExc_ValueError, "missing sub-code for L/M");
//                 return -1;
//             }

//             if (code == 'L') {
//                 const void *buf = va_arg(ap, const void *);
//                 int len          = va_arg(ap, int);

//                 PyObject *(*tx)(void *) = NULL;
//                 if (sub == 'T') {
//                     tx = va_arg(ap, PyObject *(*)(void *));
//                     if (!tx) {
//                         PyErr_SetString(PyExc_ValueError, "missing transform argument");
//                         return -1;
//                     }
//                 }

//                 arg = PyList_Create(sub, buf, len, tx);

//             } else {                     /* 'M' */
//                 const void *buf = va_arg(ap, const void *);
//                 int w = va_arg(ap, int), h = va_arg(ap, int);

//                 PyObject *(*tx)(void *) = NULL;
//                 if (sub == 'T') {
//                     tx = va_arg(ap, PyObject *(*)(void *));
//                     if (!tx) {
//                         PyErr_SetString(PyExc_ValueError, "missing transform argument");
//                         return -1;
//                     }
//                 }

//                 arg = PyMat_Create(sub, buf, w, h, tx);
//             }
//         } else { 
//             ArgBuf bufval;
//             switch (code) {
//                 case 'b': case 'c': case 'C': case 'h': 
//                 case 'H': case 'i': case 'u':
//                     bufval.i32 = va_arg(ap, int);
//                     break;
//                 case 'q':
//                     bufval.i64 = va_arg(ap, long long); 
//                     break;
//                 case 'Q':
//                     bufval.u64 = va_arg(ap, unsigned long long);     
//                     break;
//                 case 'd':
//                     bufval.d = va_arg(ap, double);
//                     break;
//                 case 's':
//                     bufval.p = va_arg(ap, const char *);
//                     break;
//                 case 'O': case 'B':
//                     bufval.p = va_arg(ap, void *);
//                     break;
//                 case 'T': {
//                     void *data = va_arg(ap, void *);
//                     PyObject *(*transform)(void *) = va_arg(ap, PyObject *(*)(void *));
//                     if (!transform) {
//                         PyErr_SetString(PyExc_ValueError, "missing transform argument");
//                         return -1;
//                     }
//                     arg = transform(data);
//                     break;
//                 }
//                 default:
//                     PyErr_Format(PyExc_ValueError, "unknown format code '%c'", code);
//                     return -1;
//             }
//             if (!arg)
//                 arg = PyConvert(code, &bufval);
//         }

//         if (!arg || PyTuple_SetItem(tuple, pos++, arg) < 0)
//             return -1;
//     }

//     *retcode_out = fmt[strlen(fmt) - 1];
//     return 0;
// }

// int py_trampoline(PyObject *cb, int n_args, const char *fmt, void* ret, ...)
// {
//     PyGILState_STATE g = PyGILState_Ensure();

//     if (validate_callable_signature(cb, n_args) != 0) {
//         fprintf(stderr, "validate failed");
//         PyErr_Print();
//         PyGILState_Release(g);
//         return -1;
//     }
//     fprintf(stderr, "test after callable");

//     PyObject *tuple = PyTuple_New(n_args);
//     if (!tuple) {
//         PyErr_SetString(PyExc_RuntimeError, "Failed to allocate Python tuple");
//         PyErr_Print();
//         PyGILState_Release(g);
//         return -1;
//     }
//     fprintf(stderr, "test after tuple");

//     /* Build args */
//     va_list args;
//     va_start(args, ret);
//     char retfmt;
//     if (PyReadArgs(fmt, tuple, args, &retfmt) != 0) {
//         va_end(args);
//         Py_DECREF(tuple);
//         PyErr_Print();
//         PyGILState_Release(g);
//         return -1;
//     }
//     fprintf(stderr, "test after readargs");

//     PyObject *result = PyObject_CallObject(cb, tuple);
//     va_end(args);
//     Py_DECREF(tuple);

//     if (!result) {
//         PyErr_Print();
//         PyGILState_Release(g);
//         return -1;
//     }

//     bool err = false;
//     switch (retfmt) {
//         case 'i': {
//             if (!PyLong_Check(result)) {
//                 PyErr_SetString(PyExc_TypeError, "Expected int return");
//                 err = true;
//                 break;
//             }
//             *(int*)ret = (int)PyLong_AsLong(result);
//             break;
//         }
//         case 'u': {
//             if (!PyLong_Check(result)) {
//                 PyErr_SetString(PyExc_TypeError, "Expected unsigned int return");
//                 err = true;
//                 break;
//             }
//             *(unsigned int*)ret = (unsigned int)PyLong_AsUnsignedLong(result);
//             break;
//         }
//         case 'd': {
//             if (!PyFloat_Check(result)) {
//                 PyErr_SetString(PyExc_TypeError, "Expected float return");
//                 err = true;
//                 break;
//             }
//             *(double*)ret = PyFloat_AsDouble(result);
//             break;
//         }
//         case 'b': {
//             if (!PyBool_Check(result)) {
//                 PyErr_SetString(PyExc_TypeError, "Expected bool return");
//                 err = true;
//                 break;
//             }
//             *(bool*)ret = (result == Py_True);
//             break;
//         }
//         case 'L': {
//             if (!PyList_Check(result)) {
//                 PyErr_SetString(PyExc_TypeError, "Expected a Python list");
//                 err = true;
//                 break;
//             }

//             Py_ssize_t n = PyList_Size(result);
//             if (n < 0) { 
//                 err = true; 
//                 break; 
//             }

//             int *out_arr = (int *)malloc((size_t)n * sizeof(int));
//             if (!out_arr) {
//                 PyErr_NoMemory();
//                 err = true;
//                 break;
//             }

//             for (Py_ssize_t i = 0; i < n; ++i) {
//                 PyObject *item = PyList_GET_ITEM(result, i);
//                 if (!PyLong_Check(item)) {
//                     PyErr_Format(PyExc_TypeError, "List element %zd is not an int", i);
//                     free(out_arr);
//                     err = true;
//                     break;
//                 }
//                 out_arr[i] = (int)PyLong_AsLong(item);
//             }
//             *(int**)ret = out_arr;
//             break;
//         }
//         case 'O': {
//             *(PyObject**)ret = result;
//             Py_INCREF(result);
//             break;
//         }
//         case 'v': {
//             /* void return: do nothing */
//             break;
//         }
//         default:
//             PyErr_Format(PyExc_ValueError, "Unknown return format code '%c'", retfmt);
//             err = true;
//     }

//     Py_DECREF(result);
//     if (err) {
//         PyErr_Print();
//         PyGILState_Release(g);
//         return -1;
//     }
//     else {
//         PyGILState_Release(g);
//         return 0;
//     }
// }

================
File: src/bridge/py_trampoline.h
================
// #ifndef PY_TRAMPOLINE_H
// #define PY_TRAMPOLINE_H

// #include <Python.h>

// /*  py_trampoline
//  *  -------------
//  *  Call a Python callable from C with typed arguments.
//  *
//  *  Usage
//  *  -----
//  *      rc = py_trampoline(cb, "(fmt)r", &ret, …args…);
//  *
//  *      • “(fmt)”  – one or more **argument codes**
//  *      • “r”      – **one return‑code**
//  *      • &ret     – pointer to C storage for the result
//  *      • …args…   – C values that match the codes in order
//  *
//  *  Argument codes
//  *  --------------
//  *      Integers (uppercase unsigned)
//  *          c/C 8‑bit   
//  *          h/H 16‑bit   
//  *          i/u 32‑bit   
//  *          q/Q 64‑bit
//  *      Other scalar 
//  *          d double    
//  *          b bool/int   
//  *          s const char*   
//  *          O PyObject*
//  *      Pointer+fn   
//  *          T void*, PyObject *(*transform)(void*)
//  *
//  *      Containers   
//  *          Lx  ist (buffer, len [ ,transform ])
//  *          Mx matrix (buffer, w ,h [ ,transform ])
//  *          *x is any element code above (including T).
//  *
//  *  Return codes
//  *  ------------
//  *      i 32‑bit int   
//  *      u 32‑bit unsigned   
//  *      d double   
//  *      b bool
//  *      O PyObject*             
//  *      v void / ignored
//  *      L list of 32-bit int
//  *
//  *  Result
//  *  ------
//  *      Returns 0 on success, ‑1 on error (Python exception is set).
//  */
// int py_trampoline(PyObject *cb, int n_args, const char *fmt, void* ret, ...);

// #endif /* PY_TRAMPOLINE_H */

================
File: src/bridge/pybridge.cpp
================
#include "cb_registration.hpp"
#include "pybridge.h"

#include <pybind11/pybind11.h>
#include <pybind11/stl.h>

namespace py  = pybind11;
using namespace pybridge;

get_deltaq_offset_cb_t     get_deltaq_offset_cb      = nullptr;
recv_frame_feedback_cb_t   recv_frame_feedback_cb    = nullptr;
recv_picture_feedback_cb_t recv_picture_feedback_cb  = nullptr;

extern "C" int *get_deltaq_offset_trampoline(SuperBlockInfo *sb_info_array, uint32_t sb_count,
                                       int32_t picture_number, int32_t frame_type, void *user)
{
    Callback &cb = g_callbacks[static_cast<int>(CallbackEnum::GetDeltaQOffset)];
    if (!cb.py_func.is_none())
        return nullptr;
    
    //...
}

extern "C" void recv_frame_feedback_trampoline(uint8_t *buffer_y, uint8_t *buffer_cb, uint8_t *buffer_cr,
                                         uint32_t picture_number, uint32_t bytes_used, uint32_t origin_x,
                                         uint32_t origin_y, uint32_t stride_y, uint32_t stride_cb, uint32_t stride_cr,
                                         uint32_t width, uint32_t height, void *user)
{
    Callback &cb = g_callbacks[static_cast<int>(CallbackEnum::RecvFrameFeedback)];
    if (cb.py_func.is_none())
        return;

    //...
}

extern "C" void recv_picture_feedback_trampoline(uint8_t *bitstream, uint32_t bitstream_size,
                                           uint32_t picture_number, void *user)
{
    Callback &cb = g_callbacks[static_cast<int>(CallbackEnum::RecvPictureFeedback)];
    if (cb.py_func.is_none())
        return;

    //...
}

================
File: src/bridge/pybridge.h
================
#ifndef PYBRIDGE_H_
#define PYBRIDGE_H_

#ifdef __cplusplus
extern "C" {
#endif

#include <stdint.h>
#include "../../../Source/API/EbSvtAv1Enc.h"

typedef int *(*get_deltaq_offset_cb_t)(SuperBlockInfo *, uint32_t,
                                       int32_t, int32_t, void *);

typedef void (*recv_frame_feedback_cb_t)(uint8_t *, uint8_t *, uint8_t *,
                                         uint32_t, uint32_t, uint32_t, uint32_t,
                                         uint32_t, uint32_t, uint32_t,
                                         uint32_t, uint32_t, void *);

typedef void (*recv_picture_feedback_cb_t)(uint8_t *, uint32_t,
                                           uint32_t, void *);

extern get_deltaq_offset_cb_t get_deltaq_offset_cb;
extern recv_frame_feedback_cb_t recv_frame_feedback_cb;
extern recv_picture_feedback_cb_t recv_picture_feedback_cb;

int  *get_deltaq_offset_trampoline (SuperBlockInfo *, uint32_t,
                                    int32_t, int32_t, void *);

void  recv_frame_feedback_trampoline(uint8_t *, uint8_t *, uint8_t *,
                                     uint32_t, uint32_t, uint32_t, uint32_t,
                                     uint32_t, uint32_t, uint32_t,
                                     uint32_t, uint32_t, void *);

void  recv_picture_feedback_trampoline(uint8_t *, uint32_t,
                                       uint32_t, void *);

#ifdef __cplusplus
}   /* extern "C" */
#endif
#endif /* PYBRIDGE_H_ */

================
File: src/pyencoder/environment/__init__.py
================
from gymnasium.envs.registration import register

register(
    id="Av1Env-v0",
    entry_point="src.environment:Av1Env"
)

================
File: src/pyencoder/environment/av1_env.py
================
import queue
import threading
from pathlib import Path
from typing import Any, Dict, Tuple

import gymnasium as gym
import numpy as np
from pyencoder.environment.utils import _probe_resolution
from pyencoder.utils.video_reader import VideoReader

# Constants
QP_MIN, QP_MAX = -3, 3  # delta QP range which will be action
SB_SIZE = 64  # superblock size


# Extending gymnasium's Env class
# https://gymnasium.farama.org/api/env/#gymnasium.Env
class Av1Env(gym.Env):
    metadata = {"render_modes": []}

    def __init__(
        self,
        video_path: str | Path,
        *,
        lambda_rd: float = 0.1,
        av1_runner: function = None,
    ):
        super().__init__()
        self.video_path = Path(video_path)
        self.video_reader = VideoReader(video_path)
        self.lambda_rd = float(lambda_rd)

        self.w_px, self.h_px = self.video_reader.get_resolution()
        self.w_sb = (self.w_px + SB_SIZE - 1) // SB_SIZE
        self.h_sb = (self.h_px + SB_SIZE - 1) // SB_SIZE

        # Action space = QP offset grid
        self.action_space = gym.spaces.MultiDiscrete(
            np.full((self.h_sb, self.w_sb), QP_MAX - QP_MIN + 1, dtype=np.int64)
        )

        # Observation space = previous frame summary
        self.observation_space = gym.spaces.Dict(
            {
                "bits": gym.spaces.Box(0, np.finfo("float32").max, (1,), np.float32),
                "psnr": gym.spaces.Box(0, np.finfo("float32").max, (1,), np.float32),
                "y_comp": gym.spaces.Box(0, 255, (self.h_px, self.w_px), np.uint8),
                "frame_number": gym.spaces.Discrete(
                    self.video_reader.get_frame_count()
                ),
                # "frame": gym.spaces.Discrete(1_000_000), guess no frame number for now
            }
        )

        # RL/encoder communication
        # self._action_q: queue.Queue[np.ndarray] = queue.Queue(maxsize=1) no need action ti

        self._frame_report_q: queue.Queue[Dict[str, Any]] = queue.Queue(maxsize=1)
        self._episode_done = threading.Event()
        self._encoder_thread: threading.Thread | None = None
        self._frame_action: np.ndarray | None = None
        self._next_frame_idx = 0
        self._terminated = False

        self.av1_runner = av1_runner
        if self.av1_runner is None:
            raise ValueError("av1_runner function must be provided.")
        self.av1_runner()

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.reset
    def reset(
        self, *, seed: int | None = None, options: dict | None = None
    ) -> Tuple[dict, dict]:
        super().reset(seed=seed)
        self.close()
        self._terminated = False
        self._next_frame_idx = 0
        self._episode_done.clear()

        # Spawn encoder worker
        self._encoder_thread = threading.Thread(target=self._encode_loop, daemon=True)
        self._encoder_thread.start()

        # Return first observation
        obs = {
            "bits": np.array([0.0], dtype=np.float32),
            "psnr": np.array([0.0], dtype=np.float32),
            "y_comp": np.zeros((self.h_px, self.w_px), dtype=np.uint8),
            "frame_number": np.array([0], dtype=np.int32),
        }
        return obs, {}

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.step
    def step(self, action: np.ndarray) -> Tuple[dict, float, bool, bool, dict]:
        if self._terminated:
            raise RuntimeError("Call reset() before step() after episode ends.")

        if action.shape != (self.h_sb, self.w_sb):
            raise ValueError(
                f"Action grid shape {action.shape} != ({self.h_sb},{self.w_sb})"
            )

        # send action to encoder
        # self._action_q.put(action.astype(np.int32, copy=False))
        obs, reward, self._terminated, _, info = self.get_frame_feedback(
            self._frame_report_q.get()
        )
        self.send_action(action)

        return obs, reward, self._terminated, False, info

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.close
    def close(self):
        if self._encoder_thread and self._encoder_thread.is_alive():
            self._episode_done.set()
            self._encoder_thread.join(timeout=1.0)

        # drain queues
        # for q in (self._action_q, self._frame_report_q):
        #     while not q.empty():
        #         q.get_nowait()

        self._encoder_thread = None

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.render
    def render(self):
        pass

    # Encoding
    # def _encode_loop(self):
    #     from mycodec import encode

    #     encode(
    #         str(self.video_path),
    #         on_superblock=self._on_superblock,
    #         on_frame_done=self._on_frame_done,
    #     )

    # use this in c callback
    def send_action(self, action: np.ndarray):
        return action, action.size

    def get_frame_feedback(self, frame_report: Dict[str, Any]):
        # Wait for encoder to finish the frame
        report = self._frame_report_q.get()  # dict with stats + next obs
        reward = self._reward_fn(report)  # scalar
        obs = report["next_obs"]

        self._terminated = report["is_last_frame"]
        self._next_frame_idx += 1

        info: dict = {}

        return obs, reward, self._terminated, False, info

    # Reward function
    def _reward_fn(self, rpt: Dict[str, Any]) -> float:
        return -float(rpt["bits"]) + self.lambda_rd * float(rpt["psnr"])

    # def _on_superblock(self, sb_stats: Dict[str, Any], sb_index: int) -> int:
    #     if self._frame_action is None:
    #         # Wait until RL has produced a grid for *this* frame
    #         self._frame_action = self._action_q.get()

    #     y, x = divmod(sb_index, self.w_sb)
    #     qp_int = int(self._frame_action[y, x])
    #     return qp_int

    # def _on_frame_done(self, frame_report: Dict[str, Any]):
    #     obs_next = {
    #         "bits": np.array([frame_report["bits"]], dtype=np.float32),
    #         "psnr": np.array([frame_report["psnr"]], dtype=np.float32),
    #         "frame": self._next_frame_idx + 1,
    #     }

    #     self._frame_report_q.put(
    #         {
    #             **frame_report,
    #             "next_obs": obs_next,
    #             "is_last_frame": bool(frame_report.get("last_frame", False)),
    #         }
    #     )
    #     self._frame_action = None

    #     if frame_report.get("last_frame", False):
    #         self._episode_done.set()

================
File: src/pyencoder/utils/video_reader.py
================
# import enum
# from pathlib import Path
# from typing import Optional, Tuple

# import cv2
# import numpy as np
# from skimage.metrics import structural_similarity as ssim


# class VideoComponent(enum.Enum):
#     Y = "Y"
#     Cb = "Cb"
#     Cr = "Cr"


# class VideoReader:
#     def __init__(self, path: str):
#         self.path = path
#         self.cap = cv2.VideoCapture(path)
#         if not self.cap.isOpened():
#             raise ValueError(f"Cannot open video file: {path}")
#         self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
#         self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

#     def read(self) -> Optional[np.ndarray]:
#         ret, frame = self.cap.read()
#         return frame if ret else None

#     def release(self):
#         self.cap.release()

#     def get_resolution(self) -> Tuple[int, int]:
#         return self.width, self.height

#     def read_ycbcr_components(
#         self, frame_number: int
#     ) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray]]:
#         self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
#         frame = self.read()
#         if frame is None:
#             return None
#         ycbcr = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
#         y, cr, cb = cv2.split(ycbcr)
#         return y, cb, cr  # Return in standard order

#     def read_ycbcr_components_chopped(
#         self,
#         frame_number: int,
#         left_top: Tuple[int, int],
#         right_bottom: Tuple[int, int],
#     ) -> Optional[Tuple[np.ndarray, np.ndarray, np.ndarray]]:
#         self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
#         frame = self.read()
#         if frame is None:
#             return None
#         ycbcr = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)
#         y, cr, cb = cv2.split(ycbcr)
#         y = y[left_top[1] : right_bottom[1], left_top[0] : right_bottom[0]]
#         cb = cb[left_top[1] : right_bottom[1], left_top[0] : right_bottom[0]]
#         cr = cr[left_top[1] : right_bottom[1], left_top[0] : right_bottom[0]]
#         return y, cb, cr

#     def get_frame_count(self) -> int:
#         return int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

#     def render_frame_number(self, frame_number: int):
#         self.cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
#         frame = self.read()
#         if frame is not None:
#             self.render_frame(frame)

#     def render_frame(self, frame: np.ndarray):
#         cv2.imshow("Frame", frame)
#         cv2.waitKey(0)
#         cv2.destroyAllWindows()

#     @staticmethod
#     def render_single_component(
#         component_array: np.ndarray, component_type: VideoComponent
#     ):
#         cv2.imshow(str(component_type.value), component_array)
#         cv2.waitKey(0)
#         cv2.destroyAllWindows()

#     @staticmethod
#     def render_components(y: np.ndarray, cb: np.ndarray, cr: np.ndarray):
#         # OpenCV uses Y, Cr, Cb order
#         ycbcr_image = cv2.merge((y, cr, cb))

#         bgr_image = cv2.cvtColor(ycbcr_image, cv2.COLOR_YCrCb2BGR)
#         cv2.imshow("BGR", bgr_image)
#         cv2.waitKey(0)
#         cv2.destroyAllWindows()

#     @staticmethod
#     def calculate_psnr(original: np.ndarray, compressed: np.ndarray) -> float:
#         if original.shape != compressed.shape:
#             raise ValueError("Original and compressed images must have the same shape.")

#         mse = np.mean(
#             (original.astype(np.float64) - compressed.astype(np.float64)) ** 2
#         )
#         if mse == 0:
#             return float("inf")
#         PIXEL_MAX = 255.0
#         return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))

#     @staticmethod
#     def calculate_ssim(original: np.ndarray, compressed: np.ndarray) -> float:
#         if original.shape != compressed.shape:
#             raise ValueError("Original and compressed images must have the same shape.")
#         return ssim(
#             original,
#             compressed,
#             data_range=original.max() - original.min(),
#             multichannel=True,
#         )

#     @staticmethod
#     def calculate_mse(original: np.ndarray, compressed: np.ndarray) -> float:
#         if original.shape != compressed.shape:
#             raise ValueError("Original and compressed images must have the same shape.")
#         return np.mean((original - compressed) ** 2)


# # simple test
# if __name__ == "__main__":
#     reader = VideoReader("Data\\akiyo_qcif.y4m")

#     reader.get_resolution()
#     reader.get_frame_count()
#     y, cb, cr = reader.read_ycbcr_components(1)

#     reader.render_single_component(y, VideoComponent.Y)

#     VideoReader.render_components(y, cb, cr)

================
File: src/pyencoder/__init__.py
================
from importlib import import_module as _imp

_svtapp = _imp("._svtapp", package="pyencoder")
_run = _svtapp.run
_register = _svtapp.register_callbacks


def run(**kwargs):
    argv = ["svtav1"]
    for key, val in kwargs.items():
        # Determine short or long flag
        flag = f"-{key}" if len(key) == 1 else f"--{key.replace('_', '-')}"

        # Convert value to string appropriately
        if isinstance(val, bool):
            argv.extend([flag, "1" if val else "0"])
        else:
            argv.extend([flag, str(val)])

    print(argv)
    _run(argv)


def register_callbacks(*, get_deltaq_offset=None, frame_feedback=None, picture_feedback=None):
    _register(get_deltaq_offset, frame_feedback, picture_feedback)

================
File: src/pyencoder/_binding.cpp
================
#define main app_main
#include "../Source/App/app_main.c"
#undef main

#ifndef SVT_ENABLE_USER_CALLBACKS
#define SVT_ENABLE_USER_CALLBACKS 1
#endif

#include <pybind11/pybind11.h>

#include "../bridge/cb_validation.hpp"
#include "../bridge/cb_registration.hpp"
#include "../bridge/pybridge.h"

#include "../Source/Lib/Globals/enc_callbacks.h"
#include "../Source/API/EbSvtAv1Enc.h"
#include <EbSvtAv1Enc.h>

#include <vector>
#include <string>

namespace py = pybind11;
using namespace pybridge;

// run(argv: List[str]) -> None
static py::object run(py::list py_argv)
{
    const int argc = static_cast<int>(py_argv.size());

    // Keep string storage alive for the whole call.
    std::vector<std::string> storage;
    storage.reserve(argc);

    std::vector<char *> argv;
    argv.reserve(argc + 1);

    // Parse args to argv and argc list
    for (const py::handle &item : py_argv) {
        storage.emplace_back(py::cast<std::string>(item));
        argv.push_back(const_cast<char *>(storage.back().c_str()));
    }
    argv.push_back(nullptr);

    int rc = 0;
    {
        // Release the GIL while the encoder CLI runs.
        py::gil_scoped_release release;
        rc = app_main(argc, argv.data());
        py::gil_scoped_acquire acquire;
    }

    if (rc != 0) {
        throw std::runtime_error(
            "SvtAv1EncApp returned non‑zero exit code " + std::to_string(rc));
    }

    return py::none();
}

// register_callbacks(get_deltaq_offset=None, frame_feedback=None, picture_feedback=None) -> None
static py::object register_callbacks(py::object py_get_deltaq_offset = py::none(),
                                     py::object py_frame_feedback    = py::none(),
                                     py::object py_picture_feedback  = py::none())
{
    // Store the user callables and hook up the C trampolines
    pybridge_set_cb(CallbackEnum::GetDeltaQOffset, py_get_deltaq_offset);
    pybridge_set_cb(CallbackEnum::RecvFrameFeedback, py_frame_feedback);
    pybridge_set_cb(CallbackEnum::RecvPictureFeedback, py_picture_feedback);

    // Tell SVT‑AV1 about the trampolines
    static PluginCallbacks cbs;
    cbs.user_get_deltaq_offset = get_deltaq_offset_cb;
    cbs.user_frame_feedback = recv_frame_feedback_cb;
    cbs.user_picture_feedback = recv_picture_feedback_cb;

    if (svt_av1_enc_set_callbacks(&cbs) != EB_ErrorNone) {
        throw std::runtime_error("failed to set callbacks");
    }

    return py::none();
}

PYBIND11_MODULE(_svtapp, m)
{
    m.doc() = "In‑process bindings for the SVT‑AV1 encoder CLI";

    m.def("run", &run,
          "Run the SVT‑AV1 encoder CLI in‑process.");

    m.def("register_callbacks", &register_callbacks,
          py::arg("get_deltaq_offset") = py::none(),
          py::arg("frame_feedback")    = py::none(),
          py::arg("picture_feedback")  = py::none(),
          "Attach callbacks to the SVT‑AV1 encoder.");
}

================
File: CMakeLists.txt
================
cmake_minimum_required(VERSION 3.20)
project(av1_gym_bridge LANGUAGES C CXX ASM)

add_compile_definitions(SVT_ENABLE_USER_CALLBACKS)

# 1.  Bring in the upstream SVT‑AV1 build (core only, static)
set(BUILD_SHARED_LIBS OFF CACHE BOOL "" FORCE)
set(BUILD_APPS        OFF CACHE BOOL "" FORCE)
set(CMAKE_POSITION_INDEPENDENT_CODE ON)

add_subdirectory(
    ${CMAKE_CURRENT_LIST_DIR}/..
    ${CMAKE_CURRENT_BINARY_DIR}/svtcore
    EXCLUDE_FROM_ALL)

find_package(Threads REQUIRED)
find_package(Python3 REQUIRED COMPONENTS Interpreter Development)

# 2.  Safe‑string library  (strcpy_s, strncpy_s, …)
file(GLOB SAFE_SRC
     "${CMAKE_CURRENT_LIST_DIR}/../third_party/safestringlib/*.c")

add_library(safeclib STATIC ${SAFE_SRC})
target_include_directories(safeclib PUBLIC
    "${CMAKE_CURRENT_LIST_DIR}/../third_party/safestringlib")

# 3.  Plugin callbacks (defines svt_av1_enc_set_callbacks / plugin_cbs)
add_library(svtav1_plugin STATIC
    "${CMAKE_CURRENT_LIST_DIR}/../Source/Lib/Globals/enc_callbacks.c")

target_include_directories(svtav1_plugin PRIVATE
    "${CMAKE_CURRENT_LIST_DIR}/.."
    "${CMAKE_CURRENT_LIST_DIR}/../Source"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/Lib"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/API")

target_link_libraries(svtav1_plugin PRIVATE Threads::Threads)

# 4.  Re‑build Source/App/ as a static lib, renaming main()
file(GLOB APP_SRC "${CMAKE_CURRENT_LIST_DIR}/../Source/App/*.c")
add_library(svtav1_app STATIC ${APP_SRC})

target_compile_definitions(svtav1_app PRIVATE main=svt_enc_app_main)
target_include_directories(svtav1_app PUBLIC
    "${CMAKE_CURRENT_LIST_DIR}/.."
    "${CMAKE_CURRENT_LIST_DIR}/../Source"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/App"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/API")

target_link_libraries(svtav1_app PUBLIC Threads::Threads safeclib)

# 5.  Build the Python extension  _svtapp.{so,dylib,pyd}
add_library(_svtapp MODULE
    src/bridge/pybridge.cpp
    src/bridge/cb_registration.cpp
    src/bridge/cb_validation.cpp
    src/bridge/py_trampoline.cpp
    src/pyencoder/_binding.cpp
    "${CMAKE_CURRENT_LIST_DIR}/../Source/Lib/Globals/rl_feedback.c")

if (WIN32)
    set_target_properties(_svtapp PROPERTIES
        OUTPUT_NAME "_svtapp"
        PREFIX ""
        SUFFIX ".pyd")
else()
    set_target_properties(_svtapp PROPERTIES PREFIX "")
endif()

target_include_directories(_svtapp PRIVATE
    "${CMAKE_CURRENT_LIST_DIR}/.."
    src/bridge
    "${CMAKE_CURRENT_LIST_DIR}/../Source"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/App"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/API"
    "${CMAKE_CURRENT_LIST_DIR}/../Source/Lib/Globals" 
    ${Python3_INCLUDE_DIRS})

target_link_libraries(_svtapp
    PRIVATE
        svtav1_plugin
        svtav1_app
        SvtAv1Enc
        safeclib
        Python3::Python
        Threads::Threads
        m)
# Install path for scikit‑build‑core editable wheels
install(TARGETS _svtapp LIBRARY DESTINATION . RUNTIME DESTINATION .)

================
File: pyproject.toml
================
[project]
name = "av1-gym"
dynamic = ["version"]
authors = [{ name = "TL26" }]
readme = "README.md"
requires-python = ">=3.9"
dependencies = ["gymnasium>=0.29", "numpy>=2.1.3", "opencv-python>= 4.10"]

[build-system]
requires = [
  "scikit-build-core>=0.11",
  "setuptools_scm>=7",
  "pybind11_stubgen>=2"
]
build-backend = "scikit_build_core.build"

[tool.scikit-build]
wheel.packages    = ["src/pyencoder"]
wheel.install-dir = "pyencoder"
install.strip = false

[tool.scikit-build.cmake]
define = { SVT_ENABLE_USER_CALLBACKS = "ON" }
args = [
    "-DCMAKE_BUILD_TYPE=Debug",
    "-DCMAKE_C_FLAGS=-g",
    "-DCMAKE_CXX_FLAGS=-g",
    "-DCMAKE_INSTALL_DO_STRIP=OFF"
]

================
File: run_env.py
================
import argparse

import pyencoder
from pyencoder.environment.av1_env import Av1Env
from stable_baselines3 import A2C

env = Av1Env(
    "Data/akiyo_qcif.y4m",
    av1_runner=lambda x: pyencoder.run(
        input="../Data/akiyo_qcif.y4m", rc=True, enable_stat_report=True
    ),
)

model = A2C("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=100000)

episodes = 5
for ep in range(episodes):
    obs = env.reset()
    done = False
    while not done:
        action, _states = model.predict(obs)
        obs, rewards, done, info = env.step(action)
        env.render()
        # print(rewards)

================
File: test.py
================
import argparse
import os
from typing import List
import pandas as pd # Import pandas
import json # For potentially serializing complex data

import pyencoder

def get_deltaq_offset(
    sb_info_list: List[dict], # List of dictionaries, each with SB info
    sb_total_count: int,      # Total number of SBs, should len(sb_info_list)
    picture_number: int,      # Current picture number
    frame_type: int           # 0 for INTER, 1 for I_SLICE (example, actual meaning depends on C)
) -> List[int]:                     # Returns an int (deltaq in C, 0 for success typically)
    """
    Calculates QP offsets for all superblocks in a frame.

    Args:
        sb_info_list: A list of dictionaries. Each dictionary is expected to contain:
            'sb_org_x': int, 'sb_org_y': int, 'sb_width': int, 'sb_height': int,
            'sb_qindex': int (QP for this specific SB), 'beta': float (TPL beta).
        offset_list_to_fill: A pre-sized list that this function must populate with
                             integer QP offsets for each superblock.
        sb_total_count: The total number of superblocks.
        picture_number: The current picture/frame number.
        frame_type: Integer representing the frame type (e.g., 1 for I_SLICE).

    Returns:
        An integer status code (typically 0 for success).
    """
    print('test')
    return [0]*sb_total_count

pyencoder.register_callbacks(get_deltaq_offset=get_deltaq_offset)
pyencoder.run(input="../../playground/akiyo_qcif.y4m", rc=True, enable_stat_report=True, tbr=500)



================================================================
End of Codebase
================================================================
