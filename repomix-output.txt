This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)

Additional Info:
----------------

================================================================
Directory Structure
================================================================
src/
  bridge/
    app_entry.c
    app_entry.h
    pybridge.c
    pybridge.h
  environment/
    __init__.py
    av1-env.py
    utils.py
  pyencoder/
    _binding.c
pyproject.toml

================================================================
Files
================================================================

================
File: src/bridge/app_entry.c
================
#include "app_main.c"

int av1_app_entry(int argc, char *argv[]) {
    return main(argc, argv);
}

================
File: src/bridge/app_entry.h
================
#ifdef __cplusplus
extern "C" {
#endif

int av1_app_entry(int argc, char *argv[]);

#ifdef __cplusplus
}
#endif

================
File: src/bridge/pybridge.c
================
#include "pybridge.h"

static PyObject *py_sb_qp_obj = NULL;
int (*py_get_qp_offset_cb)(int, int, uint64_t, uint64_t) = NULL;

static int sb_qp_trampoline(int row, int col, uint64_t s1, uint64_t s2)
{
    PyGILState_STATE st = PyGILState_Ensure();
    PyObject *ret = PyObject_CallFunction(py_sb_qp_obj, "(iiKK)", row, col, s1, s2);
    int qp = (ret && PyLong_Check(ret)) ? (int)PyLong_AsLong(ret) : 32;
    Py_XDECREF(ret);
    PyGILState_Release(st);
    return qp;
}

void pybridge_set_get_qp_offset_cb(PyObject *callable)
{
    Py_XINCREF(callable);
    Py_XDECREF(py_sb_qp_obj);
    py_sb_qp_obj = callable;
    g_py_sb_qp_cb = callable ? sb_qp_trampoline : NULL;
}

void pybridge_clear_get_qp_offset_cb(void)
{
    Py_XDECREF(py_sb_qp_obj);
    py_sb_qp_obj = NULL;
    g_py_sb_qp_cb = NULL;
}

================
File: src/bridge/pybridge.h
================
#ifndef PYTHON_GYM_H
#define PYTHON_GYM_H
#include <Python.h>

#ifdef __cplusplus
extern "C" {
#endif

// setter is called from Python
void pybridge_set_get_qp_offset_cb(PyObject *callable);
void pybridge_clear_get_qp_offset_cb(void);

extern int (*py_get_qp_offset_cb)(int row, int col, uint64_t stat1, uint64_t stat2);

#ifdef __cplusplus
}
#endif
#endif

================
File: src/environment/__init__.py
================
from gymnasium.envs.registration import register

register(
    id="Av1Env-v0",
    entry_point="src.environment:Av1Env"
)

================
File: src/environment/av1-env.py
================
import queue
import threading
import gymnasium as gym
import numpy as np
from pathlib import Path
from typing import Any, Dict, Tuple

# Constants
QP_MIN, QP_MAX = 0, 63
SB_SIZE = 64

# Extending gymnasium's Env class
# https://gymnasium.farama.org/api/env/#gymnasium.Env
class Av1Env(gym.Env):
    metadata = {"render_modes": []}

    def __init__(self, video_path: str | Path, *, lambda_rd: float = 0.1):
        super().__init__()
        self.video_path = Path(video_path)
        self.lambda_rd = float(lambda_rd)

        self.w_px, self.h_px = _probe_resolution(self.video_path)
        self.w_sb = (self.w_px + SB_SIZE - 1) // SB_SIZE
        self.h_sb = (self.h_px + SB_SIZE - 1) // SB_SIZE

        # Action space = QP offset grid
        self.action_space = gym.spaces.MultiDiscrete(
            np.full((self.h_sb, self.w_sb), QP_MAX - QP_MIN + 1, dtype=np.int64)
        )

        # Observation space = previous frame summary
        self.observation_space = gym.spaces.Dict(
            {
                "bits":  gym.spaces.Box(0, np.finfo("float32").max, (1,), np.float32),
                "psnr":  gym.spaces.Box(0, np.finfo("float32").max, (1,), np.float32),
                "frame": gym.spaces.Discrete(1_000_000),
            }
        )

        # RL/encoder communication
        self._action_q: queue.Queue[np.ndarray] = queue.Queue(maxsize=1)
        self._frame_report_q: queue.Queue[Dict[str, Any]] = queue.Queue(maxsize=1)
        self._episode_done = threading.Event()
        self._encoder_thread: threading.Thread | None = None
        self._frame_action: np.ndarray | None = None
        self._next_frame_idx = 0
        self._terminated = False

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.reset
    def reset(self, *, seed: int | None = None, options: dict | None = None) -> Tuple[dict, dict]:
        super().reset(seed=seed)
        self.close()
        self._terminated = False
        self._next_frame_idx = 0
        self._episode_done.clear()

        # Spawn encoder worker
        self._encoder_thread = threading.Thread(
            target=self._encode_loop, daemon=True
        )
        self._encoder_thread.start()

        # Return first observation
        obs = {
            "bits":  np.array([0.0], dtype=np.float32),
            "psnr":  np.array([0.0], dtype=np.float32),
            "frame": 0,
        }
        return obs, {}

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.step
    def step(self, action: np.ndarray) -> Tuple[dict, float, bool, bool, dict]:
        if self._terminated:
            raise RuntimeError("Call reset() before step() after episode ends.")

        if action.shape != (self.h_sb, self.w_sb):
            raise ValueError(f"Action grid shape {action.shape} != ({self.h_sb},{self.w_sb})")

        # Send grid to encoder (blocks until encoder requests it)
        self._action_q.put(action.astype(np.int32, copy=False))

        # Wait for encoder to finish the frame
        report = self._frame_report_q.get()            # dict with stats + next obs
        reward = self._reward_fn(report)               # scalar
        obs    = report["next_obs"]

        self._terminated = report["is_last_frame"]
        self._next_frame_idx += 1

        info: dict = {}
        return obs, reward, self._terminated, False, info

    # https://gymnasium.farama.org/api/env/#gymnasium.Env.close
    def close(self):
        if self._encoder_thread and self._encoder_thread.is_alive():
            self._episode_done.set()
            self._encoder_thread.join(timeout=1.0)
        # drain queues
        for q in (self._action_q, self._frame_report_q):
            while not q.empty():
                q.get_nowait()
        self._encoder_thread = None
    
    # https://gymnasium.farama.org/api/env/#gymnasium.Env.render
    def render(self):
        pass

    # Encoding 
    def _encode_loop(self):
        from mycodec import encode

        encode(
            str(self.video_path),
            on_superblock=self._on_superblock,
            on_frame_done=self._on_frame_done,
        )

    def _on_superblock(self, sb_stats: Dict[str, Any], sb_index: int) -> int:
        if self._frame_action is None:
            # Wait until RL has produced a grid for *this* frame
            self._frame_action = self._action_q.get()

        y, x = divmod(sb_index, self.w_sb)
        qp_int = int(self._frame_action[y, x])
        return qp_int

    def _on_frame_done(self, frame_report: Dict[str, Any]):
        obs_next = {
            "bits":  np.array([frame_report["bits"]], dtype=np.float32),
            "psnr":  np.array([frame_report["psnr"]], dtype=np.float32),
            "frame": self._next_frame_idx + 1,
        }

        self._frame_report_q.put(
            {
                **frame_report,
                "next_obs":       obs_next,
                "is_last_frame":  bool(frame_report.get("last_frame", False)),
            }
        )
        self._frame_action = None

        if frame_report.get("last_frame", False):
            self._episode_done.set()

    # Reward function
    def _reward_fn(self, rpt: Dict[str, Any]) -> float:
        return -float(rpt["bits"]) + self.lambda_rd * float(rpt["psnr"])

================
File: src/environment/utils.py
================
import cv2

def _probe_resolution(path: Path) -> Tuple[int, int]:
    cap = cv2.VideoCapture(path)
    if not cap.isOpened():
        raise IOError(f"Cannot open video file: {path}")

    # Read frame width and height
    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    cap.release()
    return width, height

================
File: src/pyencoder/_binding.c
================
#define PY_SSIZE_T_CLEAN
#include <Python.h>
#include "pybridge.h"
#include "app_entry.h"

static PyObject *
py_start_encoder(PyObject *self, PyObject *args, PyObject *kw)
{
    PyObject *py_argv, *sb_cb = NULL;
    if(!PyArg_ParseTuple(args, "O!|O", &PyList_Type, &py_argv, &sb_cb))
        return NULL;

    if(sb_cb && sb_cb != Py_None)
        pybridge_set_cb(sb_cb);
    else
        pybridge_clear();

    // build argc and argv
    Py_ssize_t argc = PyList_GET_SIZE(py_argv);
    char **argv = calloc(argc+1, sizeof(char*));
    for(Py_ssize_t i=0;i<argc;i++)
        argv[i] = PyBytes_AsString(PyUnicode_AsASCIIString(PyList_GET_ITEM(py_argv,i)));

    // Call the encoder
    int rc;
    Py_BEGIN_ALLOW_THREADS
    rc = av1_app_entry((int)argc, argv);
    Py_END_ALLOW_THREADS

    free(argv);
    if(rc) return PyErr_Format(PyExc_RuntimeError,"encoder returned %d",rc);
    Py_RETURN_NONE;
}

static PyMethodDef M[] = {
    {"run", (PyCFunction)py_start_encoder, METH_VARARGS,
     "run(argv:list[str], sb_qp_cb:callable|None)"},
    {NULL,NULL,0,NULL}
};
static struct PyModuleDef mod = {PyModuleDef_HEAD_INIT,"py_svt_run",NULL,-1,M};
PyMODINIT_FUNC PyInit_py_svt_run(void){return PyModule_Create(&mod);}

================
File: pyproject.toml
================
[project]
name = "av1-gym"
version = "0.0.1"
dependencies = ["gymnasium>=0.29", "numpy>=2.1.3", "opencv-python>= 4.10"]



================================================================
End of Codebase
================================================================
